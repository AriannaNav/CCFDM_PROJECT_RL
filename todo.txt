ðŸ§­ ROADMAP OPERATIVA â€“ NEXT STEPS

ðŸ”´ STEP 1 â€” Rendere SAC funzionante end-to-end (baseline)

PrioritÃ : MASSIMA

PerchÃ©

CCFDM si appoggia completamente a SAC.
Se SAC non gira perfettamente da solo â†’ ogni bug successivo sarÃ  impossibile da diagnosticare.

Cosa fare
	â€¢	Implementare / completare in sac.py:
	â€¢	Actor
	â€¢	Double Critic
	â€¢	Target critic
	â€¢	Î± (entropy temperature)
	â€¢	Far girare:
	â€¢	SAC only
	â€¢	senza encoder CNN
	â€¢	osservazioni state-based (MiniGrid semplificato o PointMass)

Check di successo

âœ” training stabile
âœ” reward cresce
âœ” nessun NaN / divergenza
âœ” eval.py produce curve sensate

ðŸ‘‰ NON passare oltre finchÃ© questo non Ã¨ solido.

â¸»

ðŸŸ  STEP 2 â€” Encoder CNN + SAC (pixel â†’ policy)

Qui inizi davvero â€œfrom pixelsâ€

Obiettivo
obs (RGB) â†’ Encoder â†’ latent z â†’ SAC
senza:
	â€¢	FDM
	â€¢	contrastive
	â€¢	intrinsic reward

Cosa implementare
	â€¢	encoder.py
	â€¢	CNN come SAC-AE / DrQ
	â€¢	Collegare encoder a:
	â€¢	actor
	â€¢	critic
	â€¢	Replay buffer che salva immagini

Check di successo

âœ” SAC funziona anche da pixel
âœ” piÃ¹ lento, ma non collassa
âœ” embedding z ha shape coerente ovunque

ðŸ‘‰ Questo step isola tutti i problemi visivi prima della curiositÃ .
ðŸŸ¡ STEP 3 â€” Forward Dynamics Model isolato

Qui inizi il paper, ma senza RL

Obiettivo

Allenare solo:
(z_t, a_t) â†’ zÌ‚_{t+1}
Cosa fare
	â€¢	models.py
	â€¢	Action Embedding
	â€¢	FDM (MLP)
	â€¢	Loss semplice:
	â€¢	MSE(zÌ‚, z_next)
(per ora niente InfoNCE)

Check di successo

âœ” FDM loss â†“
âœ” predizione non collassa a costante
âœ” gradiente passa correttamente

ðŸ‘‰ Se il FDM non impara qui, non imparerÃ  mai dopo.

â¸»

ðŸŸ¢ STEP 4 â€” InfoNCE senza RL

Contrastive learning puro

Obiettivo

Implementare esattamente Eq. 8 del paper:
	â€¢	positive: (zÌ‚_{t+1}, z_{t+1})
	â€¢	negatives: altri sample nel batch

Cosa fare
	â€¢	losses.py
	â€¢	InfoNCE
	â€¢	Key Encoder:
	â€¢	copia di QE
	â€¢	update solo EMA
	â€¢	Data augmentation (crop / shift)

Check di successo

âœ” loss contrastiva â†“
âœ” embedding non collassa (norm, varianza)
âœ” positive similarity > negative

ðŸ‘‰ Questo Ã¨ il cuore rappresentazionale del paper.

â¸»

ðŸ”µ STEP 5 â€” Intrinsic Reward (Curiosity Module)

Eq. 9 del paper

Obiettivo

Produrre un segnale:
	â€¢	informativo
	â€¢	non rumoroso
	â€¢	decrescente nel tempo

Cosa fare
	â€¢	SimilaritÃ  (cos / dot)
	â€¢	Normalizzazione task-agnostic
	â€¢	Decay temporale

Check di successo

âœ” intrinsic reward:
	â€¢	alto allâ€™inizio
	â€¢	decresce
âœ” non domina extrinsic reward

â¸»

ðŸŸ£ STEP 6 â€” CCFDM + SAC (full pipeline)

Finalmente tutto insieme

Pipeline completa:
obs â†’ QE â†’ z
      â†“
    FDM â†’ zÌ‚'
      â†“
 InfoNCE + curiosity
      â†“
 SAC update
 Cosa fare
	â€¢	Integrare tutto in ccfdm_agent.py
	â€¢	Allenare su:
	â€¢	MiniGrid (KeyCorridor / MultiRoom)
	â€¢	Loggare:
	â€¢	extrinsic return
	â€¢	intrinsic reward
	â€¢	contrastive loss

Check di successo

âœ” esplorazione migliore di SAC
âœ” agent sblocca zone informative
âœ” training stabile

â¸»

ðŸ§ª STEP 7 â€” Confronti sperimentali (obbligatori)

Richiesti esplicitamente nella project description  ï¿¼

Esperimenti minimi
Metodo
Atteso
SAC
baseline
SAC + Pathak curiosity
rumoroso
SAC + CCFDM
migliore esplorazione
Metriche:
	â€¢	state coverage
	â€¢	return vs steps
	â€¢	stabilitÃ  policy

â¸»

ðŸ§  STEP 8 â€” Ablation & Extensions (se avanza tempo)
	â€¢	No FDM
	â€¢	No EMA
	â€¢	InfoNCE vs Triplet
	â€¢	Peso intrinsic reward
