
Curiosity Contrastive Forward Dynamics Model (CCFDM)

This repository contains an implementation of Curiosity Contrastive Forward Dynamics Model (CCFDM) built on top of Soft Actor-Critic (SAC), following:

Nguyen et al., â€œSample-efficient Reinforcement Learning Representation Learning with Curiosity Contrastive Forward Dynamics Modelâ€, 2021

The framework combines:
	â€¢	pixel-based representation learning,
	â€¢	contrastive learning with a momentum encoder,
	â€¢	a forward dynamics model in latent space,
	â€¢	intrinsic motivation based on prediction error,
	â€¢	off-policy RL (SAC).

â¸»

1. Features
	â€¢	End-to-end training from pixels
	â€¢	Contrastive representation learning (InfoNCE)
	â€¢	Forward dynamics model for temporal consistency
	â€¢	Curiosity-driven intrinsic reward
	â€¢	Compatible with DeepMind Control Suite and MiniGrid
	â€¢	Deterministic evaluation and video rendering

 2. Project Structure
 
â”œâ”€â”€ main.py              # training entry point
â”œâ”€â”€ train_ccfdm.py       # legacy training script
â”œâ”€â”€ eval.py              # evaluation from saved checkpoint
â”œâ”€â”€ plots.py             # plot learning curves
â”œâ”€â”€ video.py             # render rollout video
â”œâ”€â”€ ccfdm_agent.py       # SAC + CCFDM agent
â”œâ”€â”€ ccfdm_modules.py     # FDM, action embedding, contrastive module
â”œâ”€â”€ encoder.py           # pixel encoder
â”œâ”€â”€ sac.py               # SAC implementation
â”œâ”€â”€ data.py              # replay buffer
â”œâ”€â”€ dmc.py               # DeepMind Control wrapper
â”œâ”€â”€ minigrid_env.py      # MiniGrid wrapper
â”œâ”€â”€ make_env.py          # environment factory
â”œâ”€â”€ losses.py            # contrastive and curiosity losses
â”œâ”€â”€ utils.py             # utilities (seed, soft update, etc.)
â””â”€â”€ logger.py            # logging utilities


Training corto (20k step)

Serve solo a verificare che tutto funzioni.
python train_ccfdm.py \
  --env dmc \
  --dmc_domain walker \
  --dmc_task walk \
  --seed 1 \
  --device mps \
  --total_steps 20000 \
  --init_random_steps 2000 \
  --update_after 1000 \
  --eval_every 5000 \
  --eval_episodes 5

ğŸ“ Output atteso:
models/ccfdm/dmc_walker_walk/seed_1/
  â”œâ”€â”€ last.pt
  â”œâ”€â”€ best.pt
logs/ccfdm/dmc_walker_walk/seed_1/
Se non vedi errori e vengono salvati i file â†’ sei a posto.


3ï¸âƒ£ Training â€œveroâ€ (paper-like)
python train_ccfdm.py \
  --env dmc \
  --dmc_domain walker \
  --dmc_task walk \
  --seed 1 \
  --device mps \
  --total_steps 500000 \
  --batch_size 512 \
  --eval_every 10000 \
  --eval_episodes 10 \
  --save_every 10000


ğŸ’¡ Altri task DMC validi:
	â€¢	cartpole swingup
	â€¢	finger spin
	â€¢	cheetah run
	â€¢	ball_in_cup catch
	â€¢	reacher easy

4ï¸âƒ£ Evaluation (policy deterministica)

Metodo diretto
python eval.py \
  --model_dir models/ccfdm/dmc_walker_walk/seed_1 \
  --episodes 10 \
  --device mps

Output:
	â€¢	mean return
	â€¢	std return

5ï¸âƒ£ Rendering / Video
python video.py \
  --model_dir models/ccfdm/dmc_walker_walk/seed_1 \
  --out_dir videos \
  --episodes 3 \
  --fps 30 \
  --device mps

ğŸ“ Output:
videos/
  â””â”€â”€ dmc_walker_walk_seed1_ep0.mp4

Se .mp4 non viene scritto:

pip install imageio-ffmpeg

6ï¸âƒ£ Tutto da main.py (come volevi tu)

âœ”ï¸ Eval + Render insieme
python main.py --eval --render \
  --model_dir models/ccfdm/dmc_walker_walk/seed_1 \
  --device mps

âœ”ï¸ ModalitÃ  subcommand (piÃ¹ pulita)
python main.py run --do_eval --do_video \
  --model_dir models/ccfdm/dmc_walker_walk/seed_1 \
  --device mps


â¸»

7ï¸âƒ£ Plot delle curve (stile Fig.5)
python plots.py \
  --log_dir logs/ccfdm/dmc_walker_walk/seed_1

Output:
logs/.../fig5_eval_curve.png

8ï¸âƒ£ Workflow consigliato (ordine giusto)
	1.	âœ… Training corto (20k) â†’ verifica che tutto gira
	2.	ğŸš€ Training lungo (500k)
	3.	ğŸ“Š Eval (eval.py)
	4.	ğŸ¥ Video (video.py)
	5.	ğŸ“ˆ Plot (plots.py)

9ï¸âƒ£ Note importanti (da ricercatrice a ricercatrice)
	â€¢	Lâ€™intrinsic reward Ã¨ attiva solo in training
	â€¢	Eval e video usano policy deterministica
	â€¢	Data augmentation non Ã¨ piÃ¹ un no-op su DMC 84Ã—84
	â€¢	CCFDM Ã¨ paper-faithful (Eq.8 + Eq.9, decay singolo)